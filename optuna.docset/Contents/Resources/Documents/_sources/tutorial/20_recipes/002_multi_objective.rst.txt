
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "tutorial/20_recipes/002_multi_objective.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_tutorial_20_recipes_002_multi_objective.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_tutorial_20_recipes_002_multi_objective.py:


.. _multi_objective:

Multi-objective Optimization with Optuna
========================================

This tutorial showcases Optuna's multi-objective optimization feature by
optimizing the validation accuracy of Fashion MNIST dataset and the FLOPS of the model implemented in PyTorch.

We use `thop <https://github.com/Lyken17/pytorch-OpCounter>`_ to measure FLOPS.

.. GENERATED FROM PYTHON SOURCE LINES 12-74

.. code-block:: default


    import thop
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torchvision

    import optuna


    DEVICE = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
    DIR = ".."
    BATCHSIZE = 128
    N_TRAIN_EXAMPLES = BATCHSIZE * 30
    N_VALID_EXAMPLES = BATCHSIZE * 10


    def define_model(trial):
        n_layers = trial.suggest_int("n_layers", 1, 3)
        layers = []

        in_features = 28 * 28
        for i in range(n_layers):
            out_features = trial.suggest_int("n_units_l{}".format(i), 4, 128)
            layers.append(nn.Linear(in_features, out_features))
            layers.append(nn.ReLU())
            p = trial.suggest_float("dropout_{}".format(i), 0.2, 0.5)
            layers.append(nn.Dropout(p))

            in_features = out_features

        layers.append(nn.Linear(in_features, 10))
        layers.append(nn.LogSoftmax(dim=1))

        return nn.Sequential(*layers)


    # Defines training and evaluation.
    def train_model(model, optimizer, train_loader):
        model.train()
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)
            optimizer.zero_grad()
            F.nll_loss(model(data), target).backward()
            optimizer.step()


    def eval_model(model, valid_loader):
        model.eval()
        correct = 0
        with torch.no_grad():
            for batch_idx, (data, target) in enumerate(valid_loader):
                data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)
                pred = model(data).argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()

        accuracy = correct / N_VALID_EXAMPLES

        flops, _ = thop.profile(model, inputs=(torch.randn(1, 28 * 28).to(DEVICE),), verbose=False)
        return flops, accuracy









.. GENERATED FROM PYTHON SOURCE LINES 75-77

Define multi-objective objective function.
Objectives are FLOPS and accuracy.

.. GENERATED FROM PYTHON SOURCE LINES 77-107

.. code-block:: default

    def objective(trial):
        train_dataset = torchvision.datasets.FashionMNIST(
            DIR, train=True, download=True, transform=torchvision.transforms.ToTensor()
        )
        train_loader = torch.utils.data.DataLoader(
            torch.utils.data.Subset(train_dataset, list(range(N_TRAIN_EXAMPLES))),
            batch_size=BATCHSIZE,
            shuffle=True,
        )

        val_dataset = torchvision.datasets.FashionMNIST(
            DIR, train=False, transform=torchvision.transforms.ToTensor()
        )
        val_loader = torch.utils.data.DataLoader(
            torch.utils.data.Subset(val_dataset, list(range(N_VALID_EXAMPLES))),
            batch_size=BATCHSIZE,
            shuffle=True,
        )
        model = define_model(trial).to(DEVICE)

        optimizer = torch.optim.Adam(
            model.parameters(), trial.suggest_float("lr", 1e-5, 1e-1, log=True)
        )

        for epoch in range(10):
            train_model(model, optimizer, train_loader)
        flops, accuracy = eval_model(model, val_loader)
        return flops, accuracy









.. GENERATED FROM PYTHON SOURCE LINES 108-115

Run multi-objective optimization
--------------------------------

If your optimization problem is multi-objective,
Optuna assumes that you will specify the optimization direction for each objective.
Specifically, in this example, we want to minimize the FLOPS (we want a faster model)
and maximize the accuracy. So we set ``directions`` to ``["minimize", "maximize"]``.

.. GENERATED FROM PYTHON SOURCE LINES 115-121

.. code-block:: default

    study = optuna.create_study(directions=["minimize", "maximize"])
    study.optimize(objective, n_trials=30, timeout=300)

    print("Number of finished trials: ", len(study.trials))






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../FashionMNIST/raw/train-images-idx3-ubyte.gz
      0%|          | 0/26421880 [00:00<?, ?it/s]      0%|          | 40960/26421880 [00:00<01:14, 352074.64it/s]      0%|          | 104448/26421880 [00:00<01:07, 388256.28it/s]      1%|          | 252928/26421880 [00:00<00:34, 751233.12it/s]      3%|3         | 842752/26421880 [00:00<00:12, 2079866.83it/s]      8%|7         | 2097152/26421880 [00:00<00:05, 4828919.20it/s]     18%|#7        | 4721664/26421880 [00:00<00:02, 10830806.40it/s]     32%|###1      | 8348672/26421880 [00:00<00:01, 15980208.81it/s]     45%|####5     | 12019712/26421880 [00:01<00:00, 21464709.60it/s]     58%|#####8    | 15329280/26421880 [00:01<00:00, 23936267.79it/s]     73%|#######2  | 19182592/26421880 [00:01<00:00, 27960435.48it/s]     87%|########7 | 23061504/26421880 [00:01<00:00, 27448702.44it/s]    26422272it [00:01, 18017616.06it/s]                              
    Extracting ../FashionMNIST/raw/train-images-idx3-ubyte.gz to ../FashionMNIST/raw
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../FashionMNIST/raw/train-labels-idx1-ubyte.gz
      0%|          | 0/29515 [00:00<?, ?it/s]    29696it [00:00, 328842.56it/s]           
    Extracting ../FashionMNIST/raw/train-labels-idx1-ubyte.gz to ../FashionMNIST/raw
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../FashionMNIST/raw/t10k-images-idx3-ubyte.gz
      0%|          | 0/4422102 [00:00<?, ?it/s]      1%|          | 41984/4422102 [00:00<00:12, 341671.36it/s]      2%|2         | 105472/4422102 [00:00<00:11, 374950.96it/s]      6%|5         | 253952/4422102 [00:00<00:05, 721037.52it/s]     19%|#9        | 855040/4422102 [00:00<00:01, 2036868.37it/s]     48%|####8     | 2132992/4422102 [00:00<00:00, 4743716.33it/s]    4422656it [00:00, 5615694.35it/s]                             
    Extracting ../FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ../FashionMNIST/raw
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../FashionMNIST/raw/t10k-labels-idx1-ubyte.gz
      0%|          | 0/5148 [00:00<?, ?it/s]    6144it [00:00, 30973321.85it/s]         
    Extracting ../FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ../FashionMNIST/raw
    Processing...
    /opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/torchvision/datasets/mnist.py:479: UserWarning:

    The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)

    Done!
    Number of finished trials:  30




.. GENERATED FROM PYTHON SOURCE LINES 122-123

Check trials on pareto front visually

.. GENERATED FROM PYTHON SOURCE LINES 123-126

.. code-block:: default

    optuna.visualization.plot_pareto_front(study, target_names=["FLOPS", "accuracy"])






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/runner/work/dash-docset-optuna/dash-docset-optuna/optuna/tutorial/20_recipes/002_multi_objective.py:123: ExperimentalWarning:

    plot_pareto_front is experimental (supported from v2.4.0). The interface can change in the future.



.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
            <script src="https://cdn.plot.ly/plotly-2.6.3.min.js"></script>                <div id="22409ccb-abd0-405a-94e0-f2c8a4999b79" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("22409ccb-abd0-405a-94e0-f2c8a4999b79")) {                    Plotly.newPlot(                        "22409ccb-abd0-405a-94e0-f2c8a4999b79",                        [{"hovertemplate":"%{text}<extra>Trial</extra>","marker":{"color":[0,2,3,4,6,7,8,9,10,11,13,14,15,16,17,20,21,22,24,25,26,27,29],"colorbar":{"title":{"text":"#Trials"}},"colorscale":[[0.0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1.0,"rgb(8,48,107)"]],"line":{"color":"Grey","width":0.5}},"mode":"markers","showlegend":false,"text":["{<br>  \"number\": 0,<br>  \"values\": [<br>    47800.0,<br>    0.6453125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 55,<br>    \"dropout_0\": 0.4302494918186176,<br>    \"n_units_l1\": 72,<br>    \"dropout_1\": 0.4421443807966199,<br>    \"lr\": 0.0001388578849962825<br>  }<br>}","{<br>  \"number\": 2,<br>  \"values\": [<br>    65174.0,<br>    0.81640625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 76,<br>    \"dropout_0\": 0.4694668095879689,<br>    \"n_units_l1\": 65,<br>    \"dropout_1\": 0.41270386862227,<br>    \"lr\": 0.002277403696638118<br>  }<br>}","{<br>  \"number\": 3,<br>  \"values\": [<br>    95102.0,<br>    0.675<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 104,<br>    \"dropout_0\": 0.2881459634397171,<br>    \"n_units_l1\": 119,<br>    \"dropout_1\": 0.39967188794790465,<br>    \"lr\": 0.00011180873203921727<br>  }<br>}","{<br>  \"number\": 4,<br>  \"values\": [<br>    57350.0,<br>    0.74453125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 72,<br>    \"dropout_0\": 0.3246011642520057,<br>    \"n_units_l1\": 11,<br>    \"dropout_1\": 0.49772866141706,<br>    \"lr\": 0.0018773136968001577<br>  }<br>}","{<br>  \"number\": 6,<br>  \"values\": [<br>    101826.0,<br>    0.421875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 113,<br>    \"dropout_0\": 0.20790439980945463,<br>    \"n_units_l1\": 104,<br>    \"dropout_1\": 0.4498056506109376,<br>    \"n_units_l2\": 13,<br>    \"dropout_2\": 0.31352897900862686,<br>    \"lr\": 5.889387318358842e-05<br>  }<br>}","{<br>  \"number\": 7,<br>  \"values\": [<br>    83370.0,<br>    0.32578125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 105,<br>    \"dropout_0\": 0.42676481523029264,<br>    \"lr\": 0.07230498715787631<br>  }<br>}","{<br>  \"number\": 8,<br>  \"values\": [<br>    112128.0,<br>    0.68515625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 123,<br>    \"dropout_0\": 0.2745303671229536,<br>    \"n_units_l1\": 68,<br>    \"dropout_1\": 0.3631911650480709,<br>    \"n_units_l2\": 94,<br>    \"dropout_2\": 0.35453862555626414,<br>    \"lr\": 0.022370511453734<br>  }<br>}","{<br>  \"number\": 9,<br>  \"values\": [<br>    57444.0,<br>    0.44921875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 66,<br>    \"dropout_0\": 0.4396808633208189,<br>    \"n_units_l1\": 75,<br>    \"dropout_1\": 0.2633182933794568,<br>    \"lr\": 2.162668465692918e-05<br>  }<br>}","{<br>  \"number\": 10,<br>  \"values\": [<br>    33646.0,<br>    0.6421875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 36,<br>    \"dropout_0\": 0.21087215015310146,<br>    \"n_units_l1\": 88,<br>    \"dropout_1\": 0.4018969621208304,<br>    \"n_units_l2\": 23,<br>    \"dropout_2\": 0.24085517205237336,<br>    \"lr\": 0.00036218876253658617<br>  }<br>}","{<br>  \"number\": 11,<br>  \"values\": [<br>    74636.0,<br>    0.82890625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 94,<br>    \"dropout_0\": 0.3053290347956952,<br>    \"lr\": 0.0012603823743870069<br>  }<br>}","{<br>  \"number\": 13,<br>  \"values\": [<br>    97578.0,<br>    0.09375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 115,<br>    \"dropout_0\": 0.209799851416141,<br>    \"n_units_l1\": 32,<br>    \"dropout_1\": 0.45168423696149507,<br>    \"n_units_l2\": 89,<br>    \"dropout_2\": 0.465889181693135,<br>    \"lr\": 0.04270167208506156<br>  }<br>}","{<br>  \"number\": 14,<br>  \"values\": [<br>    73048.0,<br>    0.68203125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 92,<br>    \"dropout_0\": 0.43252309227241753,<br>    \"lr\": 0.061400016490090754<br>  }<br>}","{<br>  \"number\": 15,<br>  \"values\": [<br>    58904.0,<br>    0.784375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 71,<br>    \"dropout_0\": 0.4694887681353807,<br>    \"n_units_l1\": 40,<br>    \"dropout_1\": 0.4505890742126627,<br>    \"lr\": 0.011022978281329743<br>  }<br>}","{<br>  \"number\": 16,<br>  \"values\": [<br>    49824.0,<br>    0.73203125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 59,<br>    \"dropout_0\": 0.24248550097036745,<br>    \"n_units_l1\": 56,<br>    \"dropout_1\": 0.2861462178213108,<br>    \"n_units_l2\": 4,<br>    \"dropout_2\": 0.35699618573196423,<br>    \"lr\": 0.002088368841701093<br>  }<br>}","{<br>  \"number\": 17,<br>  \"values\": [<br>    67928.0,<br>    0.7375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 78,<br>    \"dropout_0\": 0.43163998128953474,<br>    \"n_units_l1\": 77,<br>    \"dropout_1\": 0.2511487347863273,<br>    \"lr\": 0.00032419393471758075<br>  }<br>}","{<br>  \"number\": 20,<br>  \"values\": [<br>    113835.0,<br>    0.80546875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 125,<br>    \"dropout_0\": 0.2940030619419962,<br>    \"n_units_l1\": 75,<br>    \"dropout_1\": 0.43676916025248463,<br>    \"n_units_l2\": 76,<br>    \"dropout_2\": 0.24468510605599064,<br>    \"lr\": 0.0023407981911222277<br>  }<br>}","{<br>  \"number\": 21,<br>  \"values\": [<br>    86546.0,<br>    0.66640625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 109,<br>    \"dropout_0\": 0.40056590306943296,<br>    \"lr\": 6.589678891141198e-05<br>  }<br>}","{<br>  \"number\": 22,<br>  \"values\": [<br>    81679.0,<br>    0.6609375<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 97,<br>    \"dropout_0\": 0.3009011788019768,<br>    \"n_units_l1\": 31,<br>    \"dropout_1\": 0.45942680002184566,<br>    \"n_units_l2\": 64,<br>    \"dropout_2\": 0.43155355797732836,<br>    \"lr\": 0.000388352435299599<br>  }<br>}","{<br>  \"number\": 24,<br>  \"values\": [<br>    70016.0,<br>    0.78828125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 86,<br>    \"dropout_0\": 0.4990964999975753,<br>    \"n_units_l1\": 27,<br>    \"dropout_1\": 0.23403863089470778,<br>    \"lr\": 0.004934741491591956<br>  }<br>}","{<br>  \"number\": 25,<br>  \"values\": [<br>    26202.0,<br>    0.63046875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 33,<br>    \"dropout_0\": 0.2657845500058432,<br>    \"lr\": 0.04285408573449517<br>  }<br>}","{<br>  \"number\": 26,<br>  \"values\": [<br>    80194.0,<br>    0.5171875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 101,<br>    \"dropout_0\": 0.25880035625487385,<br>    \"lr\": 1.4496159644345501e-05<br>  }<br>}","{<br>  \"number\": 27,<br>  \"values\": [<br>    88928.0,<br>    0.81640625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 112,<br>    \"dropout_0\": 0.22558494440279736,<br>    \"lr\": 0.0005175103298415643<br>  }<br>}","{<br>  \"number\": 29,<br>  \"values\": [<br>    43454.0,<br>    0.36015625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 53,<br>    \"dropout_0\": 0.37499260434474024,<br>    \"n_units_l1\": 6,<br>    \"dropout_1\": 0.422626516022783,<br>    \"n_units_l2\": 99,<br>    \"dropout_2\": 0.46371518757348157,<br>    \"lr\": 0.009135869219689566<br>  }<br>}"],"x":[47800.0,65174.0,95102.0,57350.0,101826.0,83370.0,112128.0,57444.0,33646.0,74636.0,97578.0,73048.0,58904.0,49824.0,67928.0,113835.0,86546.0,81679.0,70016.0,26202.0,80194.0,88928.0,43454.0],"y":[0.6453125,0.81640625,0.675,0.74453125,0.421875,0.32578125,0.68515625,0.44921875,0.6421875,0.82890625,0.09375,0.68203125,0.784375,0.73203125,0.7375,0.80546875,0.66640625,0.6609375,0.78828125,0.63046875,0.5171875,0.81640625,0.36015625],"type":"scatter"},{"hovertemplate":"%{text}<extra>Best Trial</extra>","marker":{"color":[1,5,12,18,19,23,28],"colorbar":{"title":{"text":"#Best trials"},"x":1.1,"xpad":40},"colorscale":[[0.0,"rgb(255,245,240)"],[0.125,"rgb(254,224,210)"],[0.25,"rgb(252,187,161)"],[0.375,"rgb(252,146,114)"],[0.5,"rgb(251,106,74)"],[0.625,"rgb(239,59,44)"],[0.75,"rgb(203,24,29)"],[0.875,"rgb(165,15,21)"],[1.0,"rgb(103,0,13)"]],"line":{"color":"Grey","width":0.5}},"mode":"markers","showlegend":false,"text":["{<br>  \"number\": 1,<br>  \"values\": [<br>    24536.0,<br>    0.2875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 28,<br>    \"dropout_0\": 0.3232436465872424,<br>    \"n_units_l1\": 68,<br>    \"dropout_1\": 0.3082704776777909,<br>    \"lr\": 1.013045165685322e-05<br>  }<br>}","{<br>  \"number\": 5,<br>  \"values\": [<br>    19854.0,<br>    0.2<br>  ],<br>  \"params\": {<br>    \"n_layers\": 3,<br>    \"n_units_l0\": 17,<br>    \"dropout_0\": 0.20817817355653387,<br>    \"n_units_l1\": 62,<br>    \"dropout_1\": 0.39590541062747875,<br>    \"n_units_l2\": 76,<br>    \"dropout_2\": 0.22124180021471718,<br>    \"lr\": 1.9385361724720897e-05<br>  }<br>}","{<br>  \"number\": 12,<br>  \"values\": [<br>    55580.0,<br>    0.83203125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 70,<br>    \"dropout_0\": 0.42942733324713356,<br>    \"lr\": 0.0023276295094842117<br>  }<br>}","{<br>  \"number\": 18,<br>  \"values\": [<br>    11572.0,<br>    0.1890625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 2,<br>    \"n_units_l0\": 13,<br>    \"dropout_0\": 0.4922809388912322,<br>    \"n_units_l1\": 60,<br>    \"dropout_1\": 0.4869184299329098,<br>    \"lr\": 0.03453735133511713<br>  }<br>}","{<br>  \"number\": 19,<br>  \"values\": [<br>    25408.0,<br>    0.79921875<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 32,<br>    \"dropout_0\": 0.2026807408979259,<br>    \"lr\": 0.0016815250702579187<br>  }<br>}","{<br>  \"number\": 23,<br>  \"values\": [<br>    31760.0,<br>    0.81953125<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 40,<br>    \"dropout_0\": 0.37513328123356277,<br>    \"lr\": 0.007613461808071423<br>  }<br>}","{<br>  \"number\": 28,<br>  \"values\": [<br>    86546.0,<br>    0.85625<br>  ],<br>  \"params\": {<br>    \"n_layers\": 1,<br>    \"n_units_l0\": 109,<br>    \"dropout_0\": 0.2235330747182791,<br>    \"lr\": 0.005769156872059758<br>  }<br>}"],"x":[24536.0,19854.0,55580.0,11572.0,25408.0,31760.0,86546.0],"y":[0.2875,0.2,0.83203125,0.1890625,0.79921875,0.81953125,0.85625],"type":"scatter"}],                        {"title":{"text":"Pareto-front Plot"},"xaxis":{"title":{"text":"FLOPS"}},"yaxis":{"title":{"text":"accuracy"}},"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}}},                        {"responsive": true}                    )                };                            </script>        </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 127-128

Learn which hyperparameters are affecting the flops most with hyperparameter importance.

.. GENERATED FROM PYTHON SOURCE LINES 128-131

.. code-block:: default

    optuna.visualization.plot_param_importances(
        study, target=lambda t: t.values[0], target_name="flops"
    )





.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
            <script src="https://cdn.plot.ly/plotly-2.6.3.min.js"></script>                <div id="ef28863d-6827-4c40-8b9d-045ac4f1e155" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("ef28863d-6827-4c40-8b9d-045ac4f1e155")) {                    Plotly.newPlot(                        "ef28863d-6827-4c40-8b9d-045ac4f1e155",                        [{"cliponaxis":false,"hovertemplate":["lr (LogUniformDistribution): 0.0006840357832689963<extra></extra>","n_layers (IntUniformDistribution): 0.002583708291952329<extra></extra>","dropout_0 (UniformDistribution): 0.005566922729841815<extra></extra>","n_units_l0 (IntUniformDistribution): 0.9911653331949368<extra></extra>"],"marker":{"color":"rgb(66,146,198)"},"orientation":"h","text":["0.0006840357832689963","0.002583708291952329","0.005566922729841815","0.9911653331949368"],"textposition":"outside","texttemplate":"%{text:.2f}","x":[0.0006840357832689963,0.002583708291952329,0.005566922729841815,0.9911653331949368],"y":["lr","n_layers","dropout_0","n_units_l0"],"type":"bar"}],                        {"showlegend":false,"title":{"text":"Hyperparameter Importances"},"xaxis":{"title":{"text":"Importance for flops"}},"yaxis":{"title":{"text":"Hyperparameter"}},"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}}},                        {"responsive": true}                    )                };                            </script>        </div>
    </div>
    <br />
    <br />


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  24.565 seconds)


.. _sphx_glr_download_tutorial_20_recipes_002_multi_objective.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: 002_multi_objective.py <002_multi_objective.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: 002_multi_objective.ipynb <002_multi_objective.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
